{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duong4595/ib9cw0-text-analytics-23-24/blob/main/Copy_of_Simple_Language_Model_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Simple Language Model\n",
        "We will explore creating a simple language model based on word (token) embeddings. We will use `tinyshakespeare.txt` to train the language model."
      ],
      "metadata": {
        "id": "3xvfc50c3q5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings\n",
        "We will use the `gensim` library, which provides straightforward implementations of `word2vec`, to create word embeddings using the CBOW model. To keep it simple, we will create embeddings of size 5."
      ],
      "metadata": {
        "id": "WcvwuYiDf-SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "import requests\n",
        "\n",
        "# URL to the raw text file on GitHub\n",
        "url = 'https://raw.githubusercontent.com/RDGopal/IB9CW0-Text-Analytics/main/Data/tinyshakespeare.txt'\n",
        "\n",
        "# Use requests to get the content of the file\n",
        "response = requests.get(url)\n",
        "\n",
        "# Ensure the request was successful\n",
        "if response.status_code == 200:\n",
        "    s_text = response.text\n",
        "    # Continue processing the text as needed\n",
        "else:\n",
        "    print(\"Failed to retrieve the file. Status code:\", response.status_code)\n",
        "\n",
        "# Print the first 500 characters\n",
        "print(s_text[:500])\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(s_text)\n",
        "\n",
        "# Organize the tokens into sentences, Word2Vec needs data in the format of list of lists of tokens\n",
        "sentences = [tokens[i:i+100] for i in range(0, len(tokens), 100)]\n",
        "\n",
        "# Train the CBOW model\n",
        "word2vec_model = Word2Vec(sentences, vector_size=5, window=5, min_count=1, sg=0)"
      ],
      "metadata": {
        "id": "hcLXYLQuJa-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d52bbb-4b60-49d9-9f17-67744f4f64f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizer\n",
        "Once we get the embeddings, we will store the words (tokens), token ids, and embeddings in a dataframe.\n",
        "\n",
        "Note that the number of distinct words (tokens) is 14310. This is the size of our vocabulary."
      ],
      "metadata": {
        "id": "it6haWBx9wI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Create a DataFrame to store word, token_id, and embedding\n",
        "data = {\n",
        "    'word': [],\n",
        "    'token_id': [],\n",
        "    'embedding': []\n",
        "}\n",
        "\n",
        "for idx, word in enumerate(word2vec_model.wv.index_to_key):\n",
        "    data['word'].append(word)\n",
        "    data['token_id'].append(idx)\n",
        "    data['embedding'].append(word2vec_model.wv[word].tolist())  # convert numpy array to list for easier handling in DataFrame\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "ut2FlOwE90d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3f6674-25c9-44e0-d93a-84b0265335e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             word  token_id                                          embedding\n",
            "0               ,         0  [-0.2139173150062561, 1.6443589925765991, 4.50...\n",
            "1               :         1  [3.2466704845428467, 2.541710138320923, 4.8088...\n",
            "2               .         2  [2.82372784614563, 2.2152528762817383, 4.49781...\n",
            "3             the         3  [-1.2569156885147095, -1.560045599937439, 4.52...\n",
            "4               I         4  [0.9207433462142944, 4.367117881774902, 7.9074...\n",
            "...           ...       ...                                                ...\n",
            "14305  misbehaved     14305  [-0.006695118732750416, 0.16023458540439606, -...\n",
            "14306   Happiness     14306  [-0.08563660085201263, 0.14777077734470367, -0...\n",
            "14307     slew'st     14307  [-0.14825233817100525, -0.09676516056060791, 0...\n",
            "14308   dismember     14308  [0.028686027973890305, -0.05427681654691696, -...\n",
            "14309        viol     14309  [0.11942050606012344, -0.10194143652915955, 0....\n",
            "\n",
            "[14310 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Data\n",
        "Our main objective is to predict the next word (token) based on the previous 5 words (tokens). Thus, our context length is 5.\n",
        "\n",
        "We will prepare the training data such that inputs are 5 consecutive words (token) and the output to be predicted is the 6th word (token). If the input has less than 5 words (tokens), we will pad it with \\<pad>."
      ],
      "metadata": {
        "id": "sem7F-I3_qLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def generate_training_data(sentences, model_wv, window_size=5):\n",
        "    X, y = [], []\n",
        "    sequence_texts = []  # For storing the actual sequences of words\n",
        "    next_words = []  # For storing the actual next word\n",
        "    for sentence in sentences:\n",
        "        # Embed words using the Word2Vec model\n",
        "        embedded_sentence = [model_wv[word] for word in sentence if word in model_wv]\n",
        "        word_sentence = [word for word in sentence if word in model_wv]  # Keep the actual words for viewing\n",
        "        # Create sequences\n",
        "        for i in range(len(embedded_sentence)):\n",
        "            end_ix = i + window_size\n",
        "            if end_ix >= len(embedded_sentence):\n",
        "                break\n",
        "            seq_x, seq_y = embedded_sentence[i:end_ix], embedded_sentence[end_ix]\n",
        "            seq_text, next_word = word_sentence[i:end_ix], word_sentence[end_ix]\n",
        "            # Pad sequence if necessary\n",
        "            seq_x += [np.zeros(model_wv.vector_size)] * (window_size - len(seq_x))\n",
        "            seq_text += ['<pad>'] * (window_size - len(seq_text))  # Use <pad> for padding text\n",
        "            X.append(np.concatenate(seq_x))\n",
        "            y.append(seq_y)\n",
        "            sequence_texts.append(' '.join(seq_text))\n",
        "            next_words.append(next_word)\n",
        "    return np.array(X), np.array(y), sequence_texts, next_words\n",
        "\n",
        "# Assume 'sentences' and 'model.wv' have been defined\n",
        "X_train, y_train, train_sequences, train_next_words = generate_training_data(sentences, word2vec_model.wv)\n",
        "\n",
        "# Create DataFrame\n",
        "train_df = pd.DataFrame({\n",
        "    'Sequence': train_sequences,\n",
        "    'Next Word': train_next_words,\n",
        "    'X_train (Flattened Embeddings)': list(X_train),\n",
        "    'y_train (Embedding)': list(y_train)\n",
        "})\n",
        "\n"
      ],
      "metadata": {
        "id": "0uL5QTlcATvZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "ZNa29aL56NBy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "21daba12-d3f6-48e8-ebc5-8d1b3e14a1a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Sequence Next Word  \\\n",
              "0      First Citizen : Before we   proceed   \n",
              "1    Citizen : Before we proceed       any   \n",
              "2        : Before we proceed any   further   \n",
              "3  Before we proceed any further         ,   \n",
              "4       we proceed any further ,      hear   \n",
              "\n",
              "                      X_train (Flattened Embeddings)  \\\n",
              "0  [3.0321896, 1.8070849, 3.4270294, -2.8053408, ...   \n",
              "1  [1.7173121, 1.209647, 2.0685549, -1.018809, -1...   \n",
              "2  [3.2466705, 2.5417101, 4.8088984, -2.1392398, ...   \n",
              "3  [-0.024079662, 0.57426465, 1.1300638, -0.83964...   \n",
              "4  [-0.023775179, 2.944243, 7.1471043, -2.0237226...   \n",
              "\n",
              "                                 y_train (Embedding)  \n",
              "0  [0.19172128, 0.21077667, 0.5719604, -0.0292124...  \n",
              "1  [-0.97842467, 1.684992, 3.7786226, -2.8050857,...  \n",
              "2  [-0.01992005, 0.6620079, 1.1291828, -0.7801183...  \n",
              "3  [-0.21391732, 1.644359, 4.5050793, -2.5268023,...  \n",
              "4  [0.30758998, 2.4186532, 4.124135, -0.95807487,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d4149ab-6b98-48fc-a3c3-21ee272a4bde\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Next Word</th>\n",
              "      <th>X_train (Flattened Embeddings)</th>\n",
              "      <th>y_train (Embedding)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>First Citizen : Before we</td>\n",
              "      <td>proceed</td>\n",
              "      <td>[3.0321896, 1.8070849, 3.4270294, -2.8053408, ...</td>\n",
              "      <td>[0.19172128, 0.21077667, 0.5719604, -0.0292124...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Citizen : Before we proceed</td>\n",
              "      <td>any</td>\n",
              "      <td>[1.7173121, 1.209647, 2.0685549, -1.018809, -1...</td>\n",
              "      <td>[-0.97842467, 1.684992, 3.7786226, -2.8050857,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>: Before we proceed any</td>\n",
              "      <td>further</td>\n",
              "      <td>[3.2466705, 2.5417101, 4.8088984, -2.1392398, ...</td>\n",
              "      <td>[-0.01992005, 0.6620079, 1.1291828, -0.7801183...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Before we proceed any further</td>\n",
              "      <td>,</td>\n",
              "      <td>[-0.024079662, 0.57426465, 1.1300638, -0.83964...</td>\n",
              "      <td>[-0.21391732, 1.644359, 4.5050793, -2.5268023,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we proceed any further ,</td>\n",
              "      <td>hear</td>\n",
              "      <td>[-0.023775179, 2.944243, 7.1471043, -2.0237226...</td>\n",
              "      <td>[0.30758998, 2.4186532, 4.124135, -0.95807487,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d4149ab-6b98-48fc-a3c3-21ee272a4bde')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d4149ab-6b98-48fc-a3c3-21ee272a4bde button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d4149ab-6b98-48fc-a3c3-21ee272a4bde');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9dc94c6e-b86d-4370-9bd8-b6b8fdfe1bd9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9dc94c6e-b86d-4370-9bd8-b6b8fdfe1bd9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9dc94c6e-b86d-4370-9bd8-b6b8fdfe1bd9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our training dataset has 241,779 data points. Each data point has 6 words (tokens), and thus the total number of words (tokens) for training is 241,779 * 6 = 1,450,674."
      ],
      "metadata": {
        "id": "oimxyIyo7DU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape\n",
        "# train_df.head()"
      ],
      "metadata": {
        "id": "0A9NtzIFA1i5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c223d2e2-1454-4544-ca7c-96504ed8b7a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(241779, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network Design\n",
        "The neural network we will train has the following structure.\n",
        "\n",
        "1. Input layer: 25 nodes (5 words(tokens) with embedding size of 5 for each).\n",
        "2. Hidden layer: 10 nodes.\n",
        "3. Output layer: 5 nodes (for the predicted next word (token)).\n",
        "\n",
        "The total number of parameters to estimate are:\n",
        "\n",
        "25 $\\times$ 10 (edges from input to hidden layer)+\n",
        "\n",
        "10 (bias terms in the hidden layer) +\n",
        "\n",
        "10$\\times$5 (*edges from hidden layer to output layer*)+\n",
        "\n",
        "5 (*bias terms in the output layer*).\n",
        "\n",
        "Which is a total of 315 parameters that need to be estimated."
      ],
      "metadata": {
        "id": "QqdrzAMjBgBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1lAj53mvleR-XRGLuJZu21E86EjXKMbSO)\n"
      ],
      "metadata": {
        "id": "z1LRbIjluaqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def build_model(input_dim, hidden_neurons, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(hidden_neurons, input_dim=input_dim, activation='relu'),\n",
        "        Dense(output_dim, activation='linear')  # Assuming you want the raw embedding as output\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ONvwvO6yBij5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and train the model\n",
        "**Takes long to train - several hours on my machine**\n",
        "\n",
        "**I have saved the trained model (`language_model_1.h5`). To run the trained model you simply have to load the saved model and run it. **"
      ],
      "metadata": {
        "id": "LfcXWzojB6jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "nn_model = build_model(25, 10, 5)\n",
        "\n",
        "# Train the model\n",
        "nn_model.fit(X_train, y_train, epochs=20, batch_size=1)"
      ],
      "metadata": {
        "id": "jJqoKqTRBsPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model for later use"
      ],
      "metadata": {
        "id": "vTEkJ3HxL2Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Save the trained model\n",
        "nn_model.save('language_model_1.h5')  # Saves the model to your hard drive"
      ],
      "metadata": {
        "id": "Wu4GNNaLL4tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the trained model"
      ],
      "metadata": {
        "id": "OurjHgMuMBOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the model from the disk\n",
        "loaded_model = load_model('language_model_1.h5')"
      ],
      "metadata": {
        "id": "VuDYOcdMLw47"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the loss function over the training data. This is useful to compare different models that predict the same outcome."
      ],
      "metadata": {
        "id": "N37dBPm-2j2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You need to prepare your data in the same way it was prepared during model training\n",
        "loss= loaded_model.evaluate(X_train, y_train)\n",
        "print(f\"Loss: {loss}\")"
      ],
      "metadata": {
        "id": "HyP7cp562CNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb262ac1-ee7b-4914-db5a-f9d04bff0e8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7556/7556 [==============================] - 12s 2ms/step - loss: 2.4441\n",
            "Loss: 2.4441378116607666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Next Word Prediction\n",
        "Once the model is trained, we can use it for the next word (token) prediction. In the following, we will return 5 most likely next words (tokens)"
      ],
      "metadata": {
        "id": "Wiv4fH5wMJ47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def predict_next_words(model, input_sequence, word_vectors, top_n=5):\n",
        "    # Predict the embedding\n",
        "    prediction = model.predict(np.array([input_sequence]))[0]\n",
        "\n",
        "    # Calculate cosine similarity with all words\n",
        "    all_similarities = cosine_similarity([prediction], word_vectors.vectors)[0]\n",
        "\n",
        "    # Find the top 5 words with the highest similarity\n",
        "    top_indices = np.argsort(-all_similarities)[:top_n]  # Negative for descending order\n",
        "    closest_words = [(word_vectors.index_to_key[i], all_similarities[i]) for i in top_indices]\n",
        "\n",
        "    return closest_words\n"
      ],
      "metadata": {
        "id": "rpXPgRCWMMmE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the prediction"
      ],
      "metadata": {
        "id": "JcqIvMm9SnO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the loaded model\n",
        "test_sequence = \"let it be done\" # @param {type:\"string\"}\n",
        "test_tokens = word_tokenize(test_sequence)\n",
        "test_embedded = [word2vec_model.wv[word] for word in test_tokens if word in word2vec_model.wv]\n",
        "test_input = np.concatenate(test_embedded[:5])  # Simplified example\n",
        "\n",
        "vector_size = 5 # the model expects 5 words in the prompt\n",
        "\n",
        "# Ensure there are exactly 5 embeddings, pad if fewer\n",
        "if len(test_embedded) < 5:\n",
        "    # Pad with zero-filled vectors\n",
        "    test_embedded += [np.zeros(vector_size) for _ in range(5 - len(test_embedded))]\n",
        "\n",
        "# Flatten the list of embeddings to match input shape, and ensure it's truncated to exactly 5 words\n",
        "test_input = np.concatenate(test_embedded[:5])\n",
        "\n",
        "predicted_words = predict_next_words(loaded_model, test_input, word2vec_model.wv)\n"
      ],
      "metadata": {
        "id": "NCt6q6IwQ1Ij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f2152e-45c9-46e8-82f0-602e6f33a39e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 99ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted next words:\")\n",
        "for word, similarity in predicted_words:\n",
        "    print(f\"{word}\")"
      ],
      "metadata": {
        "id": "9rkbPSfll_1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b46c7d-4a54-47fa-9fa7-7d20242d244e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next words:\n",
            "strike\n",
            "Doricles\n",
            "Look\n",
            "Yes\n",
            "CARLISLE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Generation with Randomness\n",
        "To make the outputted text more interesting, we will inject some randomness. We will pick the next word in the sequence of text based on the probabilities for the 20 likely next words (tokens)."
      ],
      "metadata": {
        "id": "rgUDaVHQBr1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text generation function"
      ],
      "metadata": {
        "id": "NTZHPf-PTap7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_words_with_probabilities(model, input_sequence, word_vectors, top_n=20):\n",
        "    # Predict the embedding\n",
        "    prediction = model.predict(np.array([input_sequence]))[0]\n",
        "\n",
        "    # Calculate cosine similarity with all words\n",
        "    all_similarities = cosine_similarity([prediction], word_vectors.vectors)[0]\n",
        "\n",
        "    # Get the top 5 indices and scores\n",
        "    top_indices = np.argsort(-all_similarities)[:top_n]\n",
        "    top_scores = all_similarities[top_indices]\n",
        "\n",
        "    # Convert scores to probabilities using softmax\n",
        "    top_probabilities = np.exp(top_scores) / np.sum(np.exp(top_scores))\n",
        "\n",
        "    # Ensure the probabilities sum to 1\n",
        "    top_probabilities /= top_probabilities.sum()\n",
        "\n",
        "    return [(word_vectors.index_to_key[i], top_probabilities[j]) for j, i in enumerate(top_indices)]\n",
        "\n"
      ],
      "metadata": {
        "id": "001vjNRITlNF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, initial_text, word_vectors, num_words, vector_size=5):\n",
        "    tokens = word_tokenize(initial_text)\n",
        "    current_embeddings = [word_vectors[word] for word in tokens if word in word_vectors]\n",
        "\n",
        "    generated_words = tokens.copy()\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        if len(current_embeddings) < 5:\n",
        "            padded_embeddings = current_embeddings + [np.zeros(vector_size) for _ in range(5 - len(current_embeddings))]\n",
        "        else:\n",
        "            padded_embeddings = current_embeddings[-5:]\n",
        "\n",
        "        input_sequence = np.concatenate(padded_embeddings)\n",
        "\n",
        "        next_word_options = predict_next_words_with_probabilities(model, input_sequence, word_vectors)\n",
        "\n",
        "        words, probabilities = zip(*next_word_options)\n",
        "\n",
        "        # Normalize probabilities to ensure they sum to 1\n",
        "        probabilities = np.array(probabilities)\n",
        "        probabilities /= probabilities.sum()\n",
        "\n",
        "        next_word = np.random.choice(words, p=probabilities)\n",
        "\n",
        "        generated_words.append(next_word)\n",
        "        current_embeddings.append(word_vectors[next_word])\n",
        "\n",
        "    return ' '.join(generated_words)\n",
        "\n"
      ],
      "metadata": {
        "id": "xV4savleSvB4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "initial_text = \"let it be done\" # @param {type:\"string\"}\n",
        "num_words_to_generate = 40 # @param {type:\"integer\"}\n",
        "generated_text = generate_text(loaded_model, initial_text, word2vec_model.wv, num_words_to_generate)"
      ],
      "metadata": {
        "id": "EHO-11ZSTou1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "id": "y1oqTJPaUvg1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d3cab6a1-aac0-45d9-d8f1-feeb3c214b59"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"let it be done Marcius date Gentle Yes Love liest liest boiled Love forbid assured Look Ten Doricles scope assured hither cried liest cried prepare 'Twas Love liest Doricles sweet ignorance self inheritance forbid Look date to-morrow wonder Gentle prepare Look smile CARLISLE sweet\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that this is a 'toy' example, the outputs generated are not very impressive. But this represents the right direction of travel in terms of building a language model."
      ],
      "metadata": {
        "id": "02HvMRP2-vSE"
      }
    }
  ]
}